{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Assignment - Theoretical"
      ],
      "metadata": {
        "id": "l5TUxeOEllCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tWhat is Logistic Regression, and how does it differ from Linear Regression?\n",
        "  - Logistic Regression predicts probabilities for classification (binary or multiclass), whereas Linear Regression predicts continuous values. Logistic uses a sigmoid or softmax function; Linear does not.\n",
        "2.\tWhat is the mathematical equation of Logistic Regression?\n",
        "  - P(Y=1∣X)=11+e−(β0+β1X1+⋯+βnXn)P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1X_1 + \\cdots + \\beta_nX_n)}}P(Y=1∣X)=1+e−(β0+β1X1+⋯+βnXn)1\n",
        "3.\tWhy do we use the Sigmoid function in Logistic Regression?\n",
        "  - The sigmoid function maps any real-valued number to a range between 0 and 1, making it ideal for probability outputs.\n",
        "4.\tWhat is the cost function of Logistic Regression?\n",
        "  - The Log Loss (Binary Cross Entropy):\n",
        "−1n∑[yilog⁡(pi)+(1−yi)log⁡(1−pi)]-\\frac{1}{n} \\sum \\left[y_i \\log(p_i) + (1 - y_i)\\log(1 - p_i)\\right]−n1∑[yilog(pi)+(1−yi)log(1−pi)]\n",
        "5.\tWhat is Regularization in Logistic Regression? Why is it needed?\n",
        "  -Regularization penalizes large coefficients to prevent overfitting. It's needed to improve model generalization.\n",
        "6.\tDifference between Lasso, Ridge, and Elastic Net Regression:\n",
        "  - o\tLasso (L1): Can shrink some coefficients to 0 (feature selection)\n",
        "  - o\tRidge (L2): Shrinks coefficients uniformly (keeps all features)\n",
        "  - o\tElastic Net: Combines L1 and L2 for both regularization and selection\n",
        "7.\tWhen to use Elastic Net?\n",
        "  - Use when there is multicollinearity and you want both feature selection and regularization.\n",
        "8.\tImpact of regularization parameter (λ or C):\n",
        "  - o\tLarger λ (or smaller C in sklearn) → more regularization\n",
        "  - o\tControls overfitting vs. underfitting\n",
        "9.\tKey assumptions of Logistic Regression:\n",
        "  - o\tLinearity of independent variables with log-odds\n",
        "  - o\tIndependence of observations\n",
        "  - o\tNo multicollinearity\n",
        "  - o\tLarge sample size\n",
        "10.\tAlternatives to Logistic Regression:\n",
        "  - o\tDecision Trees\n",
        "    o\tRandom Forest\n",
        "    o\tSVM\n",
        "    o\tKNN\n",
        "    o\tNaive Bayes\n",
        "    o\tNeural Networks\n",
        "11.\tClassification Evaluation Metrics:\n",
        "    o\tAccuracy\n",
        "    o\tPrecision\n",
        "    o\tRecall\n",
        "    o\tF1-Score\n",
        "    o\tROC-AUC\n",
        "    o\tConfusion Matrix\n",
        "    o\tCohen's Kappa\n",
        "    o\tMCC\n",
        "12.\tHow does class imbalance affect Logistic Regression?\n",
        "  - It biases predictions toward the majority class. Use class weights, sampling, or threshold tuning.\n",
        "13.\tWhat is Hyperparameter Tuning?\n",
        "  - Finding the optimal values for parameters like C, penalty, and solver using methods like GridSearchCV or RandomizedSearchCV.\n",
        "14.\tDifferent solvers & when to use them:\n",
        "    o\tliblinear: good for small data, supports L1\n",
        "    o\tsaga: supports L1, L2, Elastic Net, good for large data\n",
        "    o\tlbfgs: fast and stable, for L2\n",
        "    o\tnewton-cg: like lbfgs, but supports multiclass\n",
        "15.\tHow is Logistic Regression extended to multiclass?\n",
        "    o\tOne-vs-Rest (OvR): One classifier per class\n",
        "    o\tMultinomial (Softmax): A single model for all classes\n",
        "16.\tAdvantages & Disadvantages:\n",
        "    o\t Simple, interpretable, probabilistic\n",
        "    o\t Assumes linearity, limited with complex patterns\n",
        "17.\tUse cases:\n",
        "    o\tSpam detection\n",
        "    o\tDisease prediction\n",
        "    o\tCredit scoring\n",
        "    o\tCustomer churn prediction\n",
        "18.\tDifference: Softmax vs. Logistic Regression:\n",
        "    o\tLogistic (binary): outputs probability for 2 classes\n",
        "    o\tSoftmax (multiclass): outputs probabilities for all classes summing to 1\n",
        "19.\tOvR vs. Softmax:\n",
        "    o\tOvR is simple, flexible, and works well with imbalance\n",
        "    o\tSoftmax models all classes together, better for balanced data\n",
        "20.\tInterpretation of coefficients:\n",
        "  - Coefficients represent the change in log odds for a unit change in the predictor.\n"
      ],
      "metadata": {
        "id": "RLFgko9jjcpp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0xYRcaPgXML"
      },
      "source": [
        "# Logistic Regression Assignment -Practical(Python Code)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LqX-HWsgXMP",
        "outputId": "dac434de-7a36-4cc1-ee72-e2abe968f1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# 1. Load dataset, split, apply Logistic Regression, print accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbMgvjEUgXMR",
        "outputId": "30a608f2-966b-4842-a906-9f13ab9ba891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Accuracy: 0.956140350877193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 2. L1 Regularization (Lasso)\n",
        "model_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model_l1.fit(X_train, y_train)\n",
        "print(\"L1 Accuracy:\", model_l1.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_shI0NBrgXMR",
        "outputId": "fede0239-df73-4dce-f87e-dba0a400a19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 Accuracy: 0.956140350877193\n",
            "Coefficients: [[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
            "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
            "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
            "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
            "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
            "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
            "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
            "  -7.42763610e-01 -1.16960181e-01]]\n"
          ]
        }
      ],
      "source": [
        "# 3. L2 Regularization (Ridge)\n",
        "model_l2 = LogisticRegression(penalty='l2', solver='liblinear')\n",
        "model_l2.fit(X_train, y_train)\n",
        "print(\"L2 Accuracy:\", model_l2.score(X_test, y_test))\n",
        "print(\"Coefficients:\", model_l2.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOlh-oOtgXMS",
        "outputId": "020486c9-d9e5-49f0-cb18-162ca86fe902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Accuracy: 0.9649122807017544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 4. Elastic Net Regularization\n",
        "model_elastic = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n",
        "model_elastic.fit(X_train, y_train)\n",
        "print(\"Elastic Net Accuracy:\", model_elastic.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3VfVPdjgXMS",
        "outputId": "1b51cca7-1896-4b2a-b707-a221877cdb26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvR Accuracy: 0.9666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 5. Multiclass Logistic Regression with OvR\n",
        "from sklearn.datasets import load_iris\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model_ovr = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
        "model_ovr.fit(X_train, y_train)\n",
        "print(\"OvR Accuracy:\", model_ovr.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model and parameter grid\n",
        "model = LogisticRegression(max_iter=200)\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid = GridSearchCV(model, param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = grid.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Best Parameters: {grid.best_params_}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJOz5MLy2CIS",
        "outputId": "90b87acf-6fc2-4a56-d3fc-ba9e3677ba6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Initialize model and StratifiedKFold\n",
        "model = LogisticRegression(max_iter=200)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "\n",
        "# Perform cross-validation\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracies.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YvjDmef2OlC",
        "outputId": "2804b0a8-8fcd-432d-c650-32e3f9b4f0d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (assuming Iris saved as CSV)\n",
        "# For demo, load Iris and save as CSV\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "df.to_csv('iris.csv', index=False)\n",
        "\n",
        "# Read CSV\n",
        "data = pd.read_csv('iris.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tphEi8-V2Z7a",
        "outputId": "68e0e9f0-6843-4b84-e8b6-6094a8a65189"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model and parameter distribution\n",
        "model = LogisticRegression(max_iter=200)\n",
        "param_dist = {'C': uniform(0.1, 10), 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
        "\n",
        "# Perform RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(model, param_dist, n_iter=10, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = random_search.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69DjUX2F2ksa",
        "outputId": "e8a41af4-5f56-40ef-daf7-5d99a195def4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': np.float64(0.30584494295802445), 'penalty': 'l2', 'solver': 'saga'}\n",
            "Accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train OvO model\n",
        "model = OneVsOneClassifier(LogisticRegression(max_iter=200))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with OvO: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp2MY6UG2uDB",
        "outputId": "6e66b255-8de8-455b-c697-2a571496b54d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with OvO: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load binary dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and plot confusion matrix\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "gNXFnf1J2145",
        "outputId": "781e48f7-1f96-4908-a293-0378ba482ecf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12.Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,Recall, and F1-Score.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deo48rb92-cB",
        "outputId": "2e225505-2795-463b-86dc-92e5473c42bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9459\n",
            "Recall: 0.9859\n",
            "F1-Score: 0.9655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model with class weights\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with Class Weights: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKU1_LY-3FZL",
        "outputId": "26bd9266-cb9f-4c27-a8a5-c52ec661247f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Class Weights: 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14.Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Titanic dataset (assuming it's downloaded)\n",
        "# For demo, use a simplified approach\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess: Handle missing values, encode categorical variables\n",
        "data = data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].dropna()\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "X = data.drop('Survived', axis=1)\n",
        "y = data['Survived']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Titanic Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K0PXQYF3Nxy",
        "outputId": "177bbef4-7b48-4739-9a40-c3e2d8faf574"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titanic Accuracy: 0.7483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15.  Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Without scaling\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "acc_no_scale = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy without scaling: {acc_no_scale:.4f}\")\n",
        "print(f\"Accuracy with scaling: {acc_scaled:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RCJ1RaX3Vhw",
        "outputId": "7097bfd3-ced9-44e0-f318-55a1064a61d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0000\n",
            "Accuracy with scaling: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16.Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgXqeF7t3eUB",
        "outputId": "de8679d7-5249-41f3-8144-9e14bcd3b055"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17.Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model with C=0.5\n",
        "model = LogisticRegression(C=0.5, max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with C=0.5: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxDK6D5V3ldR",
        "outputId": "35ba093d-cb7d-4bab-b23a-bf4e5e9f33b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 18.Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance (coefficients)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': iris.feature_names,\n",
        "    'Coefficient': model.coef_[0]  # For one class\n",
        "})\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance.sort_values(by='Coefficient', key=abs, ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lQQ_Co13r-z",
        "outputId": "684e4455-cebc-46f6-ed92-b376a5b59335"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance:\n",
            "             Feature  Coefficient\n",
            "2  petal length (cm)    -2.375124\n",
            "3   petal width (cm)    -0.998746\n",
            "1   sepal width (cm)     0.962518\n",
            "0  sepal length (cm)    -0.393456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Cohen's Kappa\n",
        "y_pred = model.predict(X_test)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOu2eNDb3zEp",
        "outputId": "dc51f9a1-760b-408b-faf6-338484f26044"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.9053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20.Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classificatio:\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and plot Precision-Recall curve\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "ElVfB1g83-ae",
        "outputId": "9aec4ab7-ae60-40f9-bc88-3a7a6f74c74e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 21.Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Test different solvers\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=200)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {solver}: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeQDsbB94F27",
        "outputId": "a4ce971e-fba6-4228-ee09-8ad94f0018c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear: 1.0000\n",
            "Accuracy with saga: 1.0000\n",
            "Accuracy with lbfgs: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 22.Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate MCC\n",
        "y_pred = model.predict(X_test)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4zDEd-q4PdQ",
        "outputId": "7eb1dd06-19b4-48f8-afee-ce95737e2aaa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient: 0.9068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Raw data\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "acc_raw = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Standardized data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy on raw data: {acc_raw:.4f}\")\n",
        "print(f\"Accuracy on standardized data: {acc_scaled:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ono4dVMn4V77",
        "outputId": "aed746b2-6c39-4289-be8c-59b60ca96e22"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 1.0000\n",
            "Accuracy on standardized data: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 24.Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model and parameter grid for C\n",
        "model = LogisticRegression(max_iter=200)\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid = GridSearchCV(model, param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = grid.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Optimal C: {grid.best_params_['C']}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3mYrEgR4eAZ",
        "outputId": "c71ccdf2-7d74-4b02-bf8c-e6493f12eaa9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C: 1\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 25.Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, 'logistic_model.pkl')\n",
        "\n",
        "# Load model and predict\n",
        "loaded_model = joblib.load('logistic_model.pkl')\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with loaded model: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSnFwJj_4lWP",
        "outputId": "69b4be8a-980b-4e0b-8485-cdc448a5c204"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with loaded model: 1.0000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}